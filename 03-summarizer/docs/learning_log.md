# 学習ログ: 長文要約ツールの開発

03-summarizer プロジェクトの開発中に議論された、AI実装に関する重要な技術概念のまとめです。

## 1. AI開発の基礎概念

### Q. 指示チューニング (Instruction Tuning) とは？
AIに対して「どのような役割で」「どのような形式で」出力すべきかを指示することです。
単に「要約して」と頼むのではなく、System Promptを使って以下のように定義します。
- **役割**: 「あなたは優秀な編集者です」
- **制約**: 「箇条書きで出力」「100文字以内で」

### Q. トークン制限とは？
モデルごとに決まっている「一度に読める量（コンテキストウィンドウ）」の限界です。
- 制限を超えた場合、途中まで読んでくれるのではなく、**エラーが発生して一切処理されません**。
- これを防ぐために、入力前にデータを小さく分割（Chunking）する必要があります。

---

## 2. 実装ロジック (Chunking & Map-Reduce)

### Q. チャンク分割 (`split_text`) の仕組みは？
長いテキスト（文字列）を、一定のサイズごとに切り分けてリスト（配列）に変換する処理です。
- **Map処理**: 分割された各チャンクを個別に要約します。
- **Reduce処理**: 個別の要約結果を結合（`join`）して、最終的な形にまとめます。

### Q. さらに圧縮したい場合（100文字にしたい等）はどうする？
**「Map-Reduce」** または **「再帰的要約」** を採用します。

1. **Map**: 長文を分割して、それぞれを「中間要約」にする。
2. **Reduce**: 中間要約を結合して、再度AIに入力し「全体を100文字でまとめて」と指示する。
3. **ループ**: それでも長い場合は、AIが読めるサイズになるまで「分割→縮小」を繰り返す。

> **重要**: 繰り返しのたびに無理やり要約(Reduce)するのではなく、モデルの制限内に収まるまで「圧縮」のみを繰り返し、最後に一回だけ「要約(Reduce)」するのが情報の欠落を防ぐコツです。

---

## 3. トークンと文字数の関係

### Q. 「1文字 = 1トークン」ではないの？
違います。モデルや言語によって計算方法が異なります。
- **英語**: 1単語 ≒ 1トークン（効率が良い）
- **日本語**: 1文字 ≒ 1個以上のトークン（効率が悪い）
目安として、日本語は「文字数よりも実際のトークン数が多くなる」と覚えておく必要があります。

### Q. `tiktoken` を使う理由は？
Pythonの `len(text)` (文字数カウント) では、AIにとっての「本当の重さ」が測れないためです。
`tiktoken` を使うことで、モデルの仕様に合わせた正確なトークン計算が可能になり、制限ギリギリまで効率よくデータを使えます。

### Q. エンコード(Encode) / デコード(Decode) とは？
APIに渡すための変換プロセスです。
1. **Encode**: 文字列 → 数値のリスト（ここで正確な量を測って分割する）
2. **Decode**: 数値のリスト → 文字列（APIは文字列しか受け取れないため戻す）
